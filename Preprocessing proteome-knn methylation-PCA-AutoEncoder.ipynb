{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Proteome Preprocessing"
      ],
      "metadata": {
        "id": "LwsDbyrX6ffx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.impute import KNNImputer"
      ],
      "metadata": {
        "id": "5ToXE3C06l8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proteome = pd.read_csv(\"proteomeprofiling.csv\")\n",
        "proteome = proteome.drop(\"AGID\",axis=1)\n",
        "proteome = proteome.drop(\"Unnamed: 0\",axis=1)\n",
        "proteome = proteome.drop(\"lab_id\",axis=1)\n",
        "proteome = proteome.drop(\"catalog_number\",axis=1)\n",
        "proteome = proteome.drop(\"set_id\",axis=1)\n",
        "proteome.set_index('peptide_target', inplace=True)\n",
        "prot = proteome.T\n",
        "\n"
      ],
      "metadata": {
        "id": "A3xRV4Ys7jwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "na_percentages = prot.isna().mean()\n",
        "#print(na_percentages)\n",
        "features_to_drop = na_percentages[na_percentages > 0.10].index\n",
        "df = prot.drop(features_to_drop, axis=1)\n",
        "print(df.head()) #224 columns\n",
        "\n",
        "##checking remaining missing values in data\n",
        "missing_values = df.isna().sum().sum()\n",
        "print(missing_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blRdq0hzw3y0",
        "outputId": "bb5d9d2f-9f72-4314-8de6-2486055fc86e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peptide_target    1433BETA  1433EPSILON  1433ZETA     4EBP1  4EBP1_pS65  \\\n",
            "TCGA-57-1586-01A  0.393620     0.126040   0.15937 -0.409730   -0.218910   \n",
            "TCGA-OY-A56P-01A -0.002425    -0.052160  -0.46840  0.757750    0.255270   \n",
            "TCGA-59-2351-01A  0.545490     0.084225  -0.63569 -0.191272   -0.198916   \n",
            "TCGA-42-2591-01A  0.160590     0.090185  -0.68814  0.306880   -0.018480   \n",
            "TCGA-09-2055-01A -0.046622     0.027966   0.12577  0.105220    0.162250   \n",
            "\n",
            "peptide_target    4EBP1_pT37T46  4EBP1_pT70     53BP1  ACC_pS79      ACC1  \\\n",
            "TCGA-57-1586-01A       -0.60442   -0.312210  0.720560 -0.608400 -0.670380   \n",
            "TCGA-OY-A56P-01A        0.25551    0.055564  1.005300  0.742920  0.627220   \n",
            "TCGA-59-2351-01A       -0.45317    0.397741 -0.159815 -0.714920 -0.981740   \n",
            "TCGA-42-2591-01A        0.44288    0.031959  0.261600  0.024377  0.004215   \n",
            "TCGA-09-2055-01A        1.16340    0.157620  0.462810  0.331870  0.134400   \n",
            "\n",
            "peptide_target    ...      TSC1  TUBERIN  TUBERIN_pT1462    VEGFR2      XBP1  \\\n",
            "TCGA-57-1586-01A  ...  0.299080 -0.32323       -0.227700 -0.968060 -0.039341   \n",
            "TCGA-OY-A56P-01A  ...  0.473640  0.16740       -0.153980  0.184800  0.493800   \n",
            "TCGA-59-2351-01A  ... -0.310769 -0.26962        0.245991 -0.371230  0.194905   \n",
            "TCGA-42-2591-01A  ...  0.597220 -0.42760       -0.025784 -0.232950 -0.121240   \n",
            "TCGA-09-2055-01A  ...  0.816890 -1.01880       -0.291280  0.073138 -0.225100   \n",
            "\n",
            "peptide_target       XRCC1       YAP  YAP_pS127       YB1  YB1_pS102  \n",
            "TCGA-57-1586-01A  0.424520  0.048048  -0.255560  0.318840  -0.416100  \n",
            "TCGA-OY-A56P-01A  0.381390  1.168400   1.007700  0.246840  -0.221160  \n",
            "TCGA-59-2351-01A  0.182561  0.178070  -0.091507  0.122546   0.120570  \n",
            "TCGA-42-2591-01A -0.049648 -0.130450   0.112560 -0.302050   0.039102  \n",
            "TCGA-09-2055-01A -0.270720  0.713780   2.263700 -0.149610   0.482690  \n",
            "\n",
            "[5 rows x 224 columns]\n",
            "178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imputer = KNNImputer(n_neighbors=5)\n",
        "# Impute missing values\n",
        "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns, index=df.index)\n",
        "missing_values_after = df_imputed.isna().sum().sum()\n",
        "print(missing_values_after)\n",
        "df_imputed.to_csv(\"Preprocessed_Proteome_Profiling.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzxGJa6Gy79m",
        "outputId": "fef959be-cfff-4688-9b1b-508063eb5336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imputing missing values with KNN in Methylation Data"
      ],
      "metadata": {
        "id": "cit5T5y4MmzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "methyl = pd.read_csv(\"start_preprocessed_methylation.csv\")\n",
        "na_percentages = methyl.isna().mean()\n",
        "#print(na_percentages)\n",
        "features_to_drop = na_percentages[na_percentages > 0.10].index\n",
        "df = methyl.drop(features_to_drop, axis=1)\n",
        "print(df.head()) #224 columns\n",
        "\n",
        "##checking remaining missing values in data\n",
        "missing_values = df.isna().sum().sum()\n",
        "print(missing_values)"
      ],
      "metadata": {
        "id": "TB9mh7ASMscZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dimensionality reduction (PCA)"
      ],
      "metadata": {
        "id": "WXGhZN2d-0RH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import decomposition\n",
        "data = pd.read_csv(\"Multiomics_Matrix.csv\", index_col=0)\n",
        "print(data.head())\n",
        "pca = decomposition.PCA(n_components = 100) #this is used to specify the number of dominant PCA components as 100\n",
        "reduced_data = pca.fit_transform(data) #fit_transform does dimensionality reduction on pca variable\n",
        "reduced_df = pd.DataFrame(data = reduced_data, columns=[\"PC{}\".format(i+1) for i in range(100)]) #convert reduced_data array to DataFrame with define columns' names as PC#\n",
        "#reduced_df.to_csv(\"PCA_reduced.csv\")\n",
        "reduced_df.head()"
      ],
      "metadata": {
        "id": "lJord_E7_rT5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 982
        },
        "outputId": "d2fd9b4f-df8d-4ae3-87ad-2d5356a4eded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 ENSG00000211592.8  ENSG00000210082.2  ENSG00000198712.1  \\\n",
            "TCGA.04.1341.01           0.224734           0.099091           0.302345   \n",
            "TCGA.04.1343.01           0.151747           0.327017           0.401031   \n",
            "TCGA.04.1348.01           0.066397           0.080664           0.305162   \n",
            "TCGA.04.1356.01           0.005931           0.233921           0.314861   \n",
            "TCGA.04.1357.01           0.344002           0.275851           0.508974   \n",
            "\n",
            "                 ENSG00000210196.2  ENSG00000198938.2  ENSG00000198804.2  \\\n",
            "TCGA.04.1341.01           0.067116           0.248735           0.094510   \n",
            "TCGA.04.1343.01           0.127961           0.399175           0.288735   \n",
            "TCGA.04.1348.01           0.066515           0.183541           0.274356   \n",
            "TCGA.04.1356.01           0.166684           0.286909           0.312636   \n",
            "TCGA.04.1357.01           0.111716           0.403535           0.484572   \n",
            "\n",
            "                 ENSG00000198886.2  ENSG00000198888.2  ENSG00000211459.2  \\\n",
            "TCGA.04.1341.01           0.129327           0.132705           0.051874   \n",
            "TCGA.04.1343.01           0.168851           0.096748           0.122969   \n",
            "TCGA.04.1348.01           0.273752           0.095376           0.049362   \n",
            "TCGA.04.1356.01           0.454118           0.343866           0.074332   \n",
            "TCGA.04.1357.01           0.344670           0.168736           0.147129   \n",
            "\n",
            "                 ENSG00000198840.2  ...     TSC1   TUBERIN  TUBERIN_pT1462  \\\n",
            "TCGA.04.1341.01           0.293296  ...  0.41672 -0.257010         0.12637   \n",
            "TCGA.04.1343.01           0.368349  ...  0.81560 -0.155290        -0.29267   \n",
            "TCGA.04.1348.01           0.340767  ...  0.83448 -0.066564        -0.42667   \n",
            "TCGA.04.1356.01           0.378407  ...  0.23812 -0.481770        -0.24730   \n",
            "TCGA.04.1357.01           0.463132  ... -0.52129  0.070290        -0.02600   \n",
            "\n",
            "                   VEGFR2      XBP1     XRCC1       YAP  YAP_pS127       YB1  \\\n",
            "TCGA.04.1341.01 -0.001715  0.002950  0.073422 -0.170840    0.85191  0.225060   \n",
            "TCGA.04.1343.01  0.071719 -0.039753  0.330540  0.033011    0.44545  0.021179   \n",
            "TCGA.04.1348.01 -0.302890  0.032338  0.325450 -0.225760   -0.60310 -0.255940   \n",
            "TCGA.04.1356.01  0.065165 -0.122080 -0.062898  0.355690    0.87825 -0.227480   \n",
            "TCGA.04.1357.01 -0.766900 -0.076956 -0.204140 -0.012515    0.72329 -0.037633   \n",
            "\n",
            "                 YB1_pS102  \n",
            "TCGA.04.1341.01   0.475600  \n",
            "TCGA.04.1343.01   0.139510  \n",
            "TCGA.04.1348.01   0.013004  \n",
            "TCGA.04.1356.01   0.310520  \n",
            "TCGA.04.1357.01   0.061314  \n",
            "\n",
            "[5 rows x 4661 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
              "0  2.710845  0.549928 -1.166263  1.944507 -4.145044  1.482672  2.387995   \n",
              "1  1.319368  0.528615 -0.324826  0.592295  0.410556 -2.118825  1.011202   \n",
              "2  3.970343  1.238058 -0.196843 -0.425500 -3.198307 -3.103138 -2.358680   \n",
              "3  0.127341 -3.114642 -0.797632 -1.799079 -2.790215 -1.229805 -3.206285   \n",
              "4  0.929614  2.991157  4.217603  0.683554 -1.789017  0.934955  0.340328   \n",
              "\n",
              "        PC8       PC9      PC10  ...      PC91      PC92      PC93      PC94  \\\n",
              "0 -3.774356  0.772035  4.297315  ...  0.451935 -1.581391  0.240136 -1.192358   \n",
              "1 -3.895953 -0.568689  0.259516  ...  0.593728 -0.606136  0.240308  0.466284   \n",
              "2  0.624319  0.756920 -2.380142  ...  0.520131  0.766675 -0.185950 -1.285329   \n",
              "3 -3.191899  2.343451  1.304924  ... -0.052844 -0.671833 -0.623352  0.359200   \n",
              "4  0.920743  0.151112  1.523946  ...  0.209235  0.517979  0.236785 -0.219159   \n",
              "\n",
              "       PC95      PC96      PC97      PC98      PC99     PC100  \n",
              "0  0.298447  0.876938 -0.185780 -0.135905  0.250983 -0.982647  \n",
              "1 -1.194735  0.197872 -0.082481  0.191632  0.595902 -0.782070  \n",
              "2 -0.783381  0.492824 -0.675174 -0.224282 -1.262106  0.376868  \n",
              "3 -0.692394  0.439212 -0.177061  0.736226  0.484658  0.829875  \n",
              "4 -0.662587 -0.824845 -0.128102 -0.535953 -0.392996 -0.551519  \n",
              "\n",
              "[5 rows x 100 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2bd57c37-e9d0-4205-a01a-33eaf3530d74\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PC1</th>\n",
              "      <th>PC2</th>\n",
              "      <th>PC3</th>\n",
              "      <th>PC4</th>\n",
              "      <th>PC5</th>\n",
              "      <th>PC6</th>\n",
              "      <th>PC7</th>\n",
              "      <th>PC8</th>\n",
              "      <th>PC9</th>\n",
              "      <th>PC10</th>\n",
              "      <th>...</th>\n",
              "      <th>PC91</th>\n",
              "      <th>PC92</th>\n",
              "      <th>PC93</th>\n",
              "      <th>PC94</th>\n",
              "      <th>PC95</th>\n",
              "      <th>PC96</th>\n",
              "      <th>PC97</th>\n",
              "      <th>PC98</th>\n",
              "      <th>PC99</th>\n",
              "      <th>PC100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.710845</td>\n",
              "      <td>0.549928</td>\n",
              "      <td>-1.166263</td>\n",
              "      <td>1.944507</td>\n",
              "      <td>-4.145044</td>\n",
              "      <td>1.482672</td>\n",
              "      <td>2.387995</td>\n",
              "      <td>-3.774356</td>\n",
              "      <td>0.772035</td>\n",
              "      <td>4.297315</td>\n",
              "      <td>...</td>\n",
              "      <td>0.451935</td>\n",
              "      <td>-1.581391</td>\n",
              "      <td>0.240136</td>\n",
              "      <td>-1.192358</td>\n",
              "      <td>0.298447</td>\n",
              "      <td>0.876938</td>\n",
              "      <td>-0.185780</td>\n",
              "      <td>-0.135905</td>\n",
              "      <td>0.250983</td>\n",
              "      <td>-0.982647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.319368</td>\n",
              "      <td>0.528615</td>\n",
              "      <td>-0.324826</td>\n",
              "      <td>0.592295</td>\n",
              "      <td>0.410556</td>\n",
              "      <td>-2.118825</td>\n",
              "      <td>1.011202</td>\n",
              "      <td>-3.895953</td>\n",
              "      <td>-0.568689</td>\n",
              "      <td>0.259516</td>\n",
              "      <td>...</td>\n",
              "      <td>0.593728</td>\n",
              "      <td>-0.606136</td>\n",
              "      <td>0.240308</td>\n",
              "      <td>0.466284</td>\n",
              "      <td>-1.194735</td>\n",
              "      <td>0.197872</td>\n",
              "      <td>-0.082481</td>\n",
              "      <td>0.191632</td>\n",
              "      <td>0.595902</td>\n",
              "      <td>-0.782070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.970343</td>\n",
              "      <td>1.238058</td>\n",
              "      <td>-0.196843</td>\n",
              "      <td>-0.425500</td>\n",
              "      <td>-3.198307</td>\n",
              "      <td>-3.103138</td>\n",
              "      <td>-2.358680</td>\n",
              "      <td>0.624319</td>\n",
              "      <td>0.756920</td>\n",
              "      <td>-2.380142</td>\n",
              "      <td>...</td>\n",
              "      <td>0.520131</td>\n",
              "      <td>0.766675</td>\n",
              "      <td>-0.185950</td>\n",
              "      <td>-1.285329</td>\n",
              "      <td>-0.783381</td>\n",
              "      <td>0.492824</td>\n",
              "      <td>-0.675174</td>\n",
              "      <td>-0.224282</td>\n",
              "      <td>-1.262106</td>\n",
              "      <td>0.376868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.127341</td>\n",
              "      <td>-3.114642</td>\n",
              "      <td>-0.797632</td>\n",
              "      <td>-1.799079</td>\n",
              "      <td>-2.790215</td>\n",
              "      <td>-1.229805</td>\n",
              "      <td>-3.206285</td>\n",
              "      <td>-3.191899</td>\n",
              "      <td>2.343451</td>\n",
              "      <td>1.304924</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.052844</td>\n",
              "      <td>-0.671833</td>\n",
              "      <td>-0.623352</td>\n",
              "      <td>0.359200</td>\n",
              "      <td>-0.692394</td>\n",
              "      <td>0.439212</td>\n",
              "      <td>-0.177061</td>\n",
              "      <td>0.736226</td>\n",
              "      <td>0.484658</td>\n",
              "      <td>0.829875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.929614</td>\n",
              "      <td>2.991157</td>\n",
              "      <td>4.217603</td>\n",
              "      <td>0.683554</td>\n",
              "      <td>-1.789017</td>\n",
              "      <td>0.934955</td>\n",
              "      <td>0.340328</td>\n",
              "      <td>0.920743</td>\n",
              "      <td>0.151112</td>\n",
              "      <td>1.523946</td>\n",
              "      <td>...</td>\n",
              "      <td>0.209235</td>\n",
              "      <td>0.517979</td>\n",
              "      <td>0.236785</td>\n",
              "      <td>-0.219159</td>\n",
              "      <td>-0.662587</td>\n",
              "      <td>-0.824845</td>\n",
              "      <td>-0.128102</td>\n",
              "      <td>-0.535953</td>\n",
              "      <td>-0.392996</td>\n",
              "      <td>-0.551519</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 100 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bd57c37-e9d0-4205-a01a-33eaf3530d74')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2bd57c37-e9d0-4205-a01a-33eaf3530d74 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2bd57c37-e9d0-4205-a01a-33eaf3530d74');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-baa1c85e-33af-4a82-9500-637559eb4510\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-baa1c85e-33af-4a82-9500-637559eb4510')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-baa1c85e-33af-4a82-9500-637559eb4510 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dimensionality Reduction (AutoEncoder)"
      ],
      "metadata": {
        "id": "06iVi1OyF_4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "# Load required libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "import tensorflow.keras.optimizers as optimizer\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "#%%\n",
        "# Declaring file names\n",
        "# Path to input file\n",
        "ip_training_file = \"Multiomics_Matrix.csv\"\n",
        "# Path to output file\n",
        "op_file = \"AE_reduced_dataset_1.csv\"\n",
        "# Save checkpoints while training\n",
        "checkpoint_filepath = \"AE_reduced_dataset_1_{epoch:02d}_{val_loss:.2f}.hdf5\"\n",
        "# Path to save AE loss image\n",
        "fig_path =  \"AE_reduced_dataset_1_loss.png\"\n",
        "\n",
        "#%%\n",
        "# Data preprocessing\n",
        "print(\"Reading data \\n\")\n",
        "training_data = pd.read_csv(ip_training_file, index_col=0)\n",
        "training_data.shape\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, train_ground,valid_ground = train_test_split(training_data, training_data, test_size = 0.1, shuffle = True, random_state = 122131)\n",
        "X_train.shape\n",
        "X_test.shape\n",
        "\n",
        "#%%\n",
        "# Function to save weights when there is reduction in validation loss\n",
        "model_checkpoint_callback = ModelCheckpoint(filepath = checkpoint_filepath, save_weights_only = True, verbose = 1, monitor = 'val_loss', mode = 'min', save_best_only = True)\n",
        "\n",
        "# Early stopping function i.e stop training the model if the validation loss remains same for five subsequent epochs\n",
        "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 5)\n",
        "\n",
        "# Declare number of layers and nodes in each layer of AE\n",
        "# Size of input data i.e dimension of input data, required to declare number of nodes in first and last layer of AE\n",
        "ip_dim_size = X_train.shape[1]\n",
        "# Size of encoded representations\n",
        "encoding_dim_1 = 2000\n",
        "encoding_dim_2 = 1000\n",
        "encoding_dim_3 = 500\n",
        "encoding_dim_4 = 100\n",
        "\n",
        "# Declare structure of AE\n",
        "# Encoder section\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "ip_dim_shape = Input(shape = (ip_dim_size,), name=\"input_layer\")\n",
        "x = Dense(encoding_dim_1, activation='relu', kernel_initializer = 'uniform', name = 'encoder_layer_1')(ip_dim_shape)\n",
        "x = Dense(encoding_dim_2, activation='relu', kernel_initializer = 'uniform', name = 'encoder_layer_2')(x)\n",
        "x = Dense(encoding_dim_3, activation='relu', kernel_initializer = 'uniform', name = 'encoder_layer_3')(x)\n",
        "encoded = Dense(encoding_dim_4, activation='relu', kernel_initializer = 'uniform', name=\"bottleneck_layer\")(x)\n",
        "\n",
        "# Decoder section\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "y = Dense(encoding_dim_3, activation='relu', kernel_initializer = 'uniform', name=\"decoder_layer_3\")(encoded)\n",
        "y = Dense(encoding_dim_2, activation='relu', kernel_initializer = 'uniform', name=\"decoder_layer_2\")(y)\n",
        "y = Dense(encoding_dim_1, activation='relu', kernel_initializer = 'uniform', name=\"decoder_layer_1\")(y)\n",
        "decoded = Dense(ip_dim_size, activation='relu', kernel_initializer = 'uniform', name=\"op_layer\")(y)\n",
        "\n",
        "# This model maps an input to its reconstruction\n",
        "autoencoder = Model(inputs = ip_dim_shape, outputs = decoded)\n",
        "autoencoder.summary()\n",
        "\n",
        "# Hyper-paramters to train the model\n",
        "learning_rate = 0.001 # Vary or put in loop\n",
        "batch_size = 24 # Vary depending on the memory of GPU\n",
        "epochs = 200\n",
        "# Initialize required optimizer with learning rate\n",
        "opt_adam = optimizer.Adam(learning_rate = learning_rate)\n",
        "# Compile the model\n",
        "autoencoder.compile(optimizer = opt_adam, loss = 'mean_squared_error')\n",
        "\n",
        "# Train/fit the model\n",
        "estimator = autoencoder.fit(X_train, X_train, # input and output data\n",
        "                epochs = epochs,\n",
        "                batch_size = batch_size,\n",
        "                shuffle = True,\n",
        "                validation_data = (X_test, X_test), # Validation data\n",
        "                callbacks = [early_stopping_callback, model_checkpoint_callback])\n",
        "\n",
        "#%%\n",
        "# Get reduced dimensional representation\n",
        "# Get the encoder section of AE model\n",
        "encoder = Model(inputs = ip_dim_shape, outputs = encoded)\n",
        "# Get reduced dimension data for input data\n",
        "bottleneck_representation = encoder.predict(training_data)\n",
        "bottleneck_representation.shape\n",
        "# Convert result to dataframe - required to write to csv file\n",
        "bottleneck_representation_df = pd.DataFrame(data = bottleneck_representation, index = training_data.index)\n",
        "print(bottleneck_representation_df.shape)\n",
        "print(bottleneck_representation_df.iloc[0:5, 0:5])\n",
        "# Write result to csv file\n",
        "bottleneck_representation_df.to_csv(op_file, index = True)\n",
        "\n",
        "#%%\n",
        "# Obtain loss plot\n",
        "print(\"Training Loss: \", estimator.history['loss'][-1])\n",
        "print(\"Validation Loss: \", estimator.history['val_loss'][-1])\n",
        "plt.plot(estimator.history['loss'])\n",
        "plt.plot(estimator.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Validation'], loc = 'upper right')\n",
        "plt.savefig(fig_path)\n",
        "plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pW8ryXgGEWa",
        "outputId": "0513d034-ea8b-4ecb-ae6d-6fcec9e81135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading data \n",
            "\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 4661)]            0         \n",
            "                                                                 \n",
            " encoder_layer_1 (Dense)     (None, 2000)              9324000   \n",
            "                                                                 \n",
            " encoder_layer_2 (Dense)     (None, 1000)              2001000   \n",
            "                                                                 \n",
            " encoder_layer_3 (Dense)     (None, 500)               500500    \n",
            "                                                                 \n",
            " bottleneck_layer (Dense)    (None, 100)               50100     \n",
            "                                                                 \n",
            " decoder_layer_3 (Dense)     (None, 500)               50500     \n",
            "                                                                 \n",
            " decoder_layer_2 (Dense)     (None, 1000)              501000    \n",
            "                                                                 \n",
            " decoder_layer_1 (Dense)     (None, 2000)              2002000   \n",
            "                                                                 \n",
            " op_layer (Dense)            (None, 4661)              9326661   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23755761 (90.62 MB)\n",
            "Trainable params: 23755761 (90.62 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2012\n",
            "Epoch 1: val_loss improved from inf to 0.10603, saving model to AE_reduced_dataset_1_01_0.11.hdf5\n",
            "11/11 [==============================] - 8s 501ms/step - loss: 0.2012 - val_loss: 0.1060\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0901\n",
            "Epoch 2: val_loss improved from 0.10603 to 0.07732, saving model to AE_reduced_dataset_1_02_0.08.hdf5\n",
            "11/11 [==============================] - 7s 656ms/step - loss: 0.0901 - val_loss: 0.0773\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0753\n",
            "Epoch 3: val_loss improved from 0.07732 to 0.07071, saving model to AE_reduced_dataset_1_03_0.07.hdf5\n",
            "11/11 [==============================] - 8s 671ms/step - loss: 0.0753 - val_loss: 0.0707\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0708\n",
            "Epoch 4: val_loss improved from 0.07071 to 0.06857, saving model to AE_reduced_dataset_1_04_0.07.hdf5\n",
            "11/11 [==============================] - 5s 447ms/step - loss: 0.0708 - val_loss: 0.0686\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0691\n",
            "Epoch 5: val_loss improved from 0.06857 to 0.06775, saving model to AE_reduced_dataset_1_05_0.07.hdf5\n",
            "11/11 [==============================] - 7s 615ms/step - loss: 0.0691 - val_loss: 0.0677\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0685\n",
            "Epoch 6: val_loss improved from 0.06775 to 0.06735, saving model to AE_reduced_dataset_1_06_0.07.hdf5\n",
            "11/11 [==============================] - 5s 483ms/step - loss: 0.0685 - val_loss: 0.0673\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0680\n",
            "Epoch 7: val_loss improved from 0.06735 to 0.06688, saving model to AE_reduced_dataset_1_07_0.07.hdf5\n",
            "11/11 [==============================] - 7s 677ms/step - loss: 0.0680 - val_loss: 0.0669\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0678\n",
            "Epoch 8: val_loss improved from 0.06688 to 0.06685, saving model to AE_reduced_dataset_1_08_0.07.hdf5\n",
            "11/11 [==============================] - 6s 501ms/step - loss: 0.0678 - val_loss: 0.0668\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0678\n",
            "Epoch 9: val_loss improved from 0.06685 to 0.06678, saving model to AE_reduced_dataset_1_09_0.07.hdf5\n",
            "11/11 [==============================] - 6s 576ms/step - loss: 0.0678 - val_loss: 0.0668\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0677\n",
            "Epoch 10: val_loss improved from 0.06678 to 0.06676, saving model to AE_reduced_dataset_1_10_0.07.hdf5\n",
            "11/11 [==============================] - 6s 524ms/step - loss: 0.0677 - val_loss: 0.0668\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0677\n",
            "Epoch 11: val_loss did not improve from 0.06676\n",
            "11/11 [==============================] - 5s 468ms/step - loss: 0.0677 - val_loss: 0.0668\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0677\n",
            "Epoch 12: val_loss did not improve from 0.06676\n",
            "11/11 [==============================] - 7s 607ms/step - loss: 0.0677 - val_loss: 0.0668\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0677\n",
            "Epoch 13: val_loss improved from 0.06676 to 0.06674, saving model to AE_reduced_dataset_1_13_0.07.hdf5\n",
            "11/11 [==============================] - 5s 468ms/step - loss: 0.0677 - val_loss: 0.0667\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0677\n",
            "Epoch 14: val_loss improved from 0.06674 to 0.06674, saving model to AE_reduced_dataset_1_14_0.07.hdf5\n",
            "11/11 [==============================] - 7s 652ms/step - loss: 0.0677 - val_loss: 0.0667\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0677\n",
            "Epoch 15: val_loss improved from 0.06674 to 0.06673, saving model to AE_reduced_dataset_1_15_0.07.hdf5\n",
            "11/11 [==============================] - 5s 474ms/step - loss: 0.0677 - val_loss: 0.0667\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0676\n",
            "Epoch 16: val_loss improved from 0.06673 to 0.06665, saving model to AE_reduced_dataset_1_16_0.07.hdf5\n",
            "11/11 [==============================] - 6s 514ms/step - loss: 0.0676 - val_loss: 0.0666\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0675\n",
            "Epoch 17: val_loss improved from 0.06665 to 0.06658, saving model to AE_reduced_dataset_1_17_0.07.hdf5\n",
            "11/11 [==============================] - 7s 575ms/step - loss: 0.0675 - val_loss: 0.0666\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0674\n",
            "Epoch 18: val_loss improved from 0.06658 to 0.06629, saving model to AE_reduced_dataset_1_18_0.07.hdf5\n",
            "11/11 [==============================] - 6s 504ms/step - loss: 0.0674 - val_loss: 0.0663\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0669\n",
            "Epoch 19: val_loss improved from 0.06629 to 0.06547, saving model to AE_reduced_dataset_1_19_0.07.hdf5\n",
            "11/11 [==============================] - 6s 552ms/step - loss: 0.0669 - val_loss: 0.0655\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0658\n",
            "Epoch 20: val_loss improved from 0.06547 to 0.06398, saving model to AE_reduced_dataset_1_20_0.06.hdf5\n",
            "11/11 [==============================] - 6s 506ms/step - loss: 0.0658 - val_loss: 0.0640\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0636\n",
            "Epoch 21: val_loss improved from 0.06398 to 0.06185, saving model to AE_reduced_dataset_1_21_0.06.hdf5\n",
            "11/11 [==============================] - 7s 622ms/step - loss: 0.0636 - val_loss: 0.0618\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0615\n",
            "Epoch 22: val_loss improved from 0.06185 to 0.05978, saving model to AE_reduced_dataset_1_22_0.06.hdf5\n",
            "11/11 [==============================] - 6s 572ms/step - loss: 0.0615 - val_loss: 0.0598\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0599\n",
            "Epoch 23: val_loss improved from 0.05978 to 0.05887, saving model to AE_reduced_dataset_1_23_0.06.hdf5\n",
            "11/11 [==============================] - 5s 469ms/step - loss: 0.0599 - val_loss: 0.0589\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0589\n",
            "Epoch 24: val_loss improved from 0.05887 to 0.05834, saving model to AE_reduced_dataset_1_24_0.06.hdf5\n",
            "11/11 [==============================] - 7s 629ms/step - loss: 0.0589 - val_loss: 0.0583\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0581\n",
            "Epoch 25: val_loss improved from 0.05834 to 0.05761, saving model to AE_reduced_dataset_1_25_0.06.hdf5\n",
            "11/11 [==============================] - 6s 562ms/step - loss: 0.0581 - val_loss: 0.0576\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0574\n",
            "Epoch 26: val_loss improved from 0.05761 to 0.05709, saving model to AE_reduced_dataset_1_26_0.06.hdf5\n",
            "11/11 [==============================] - 7s 677ms/step - loss: 0.0574 - val_loss: 0.0571\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0566\n",
            "Epoch 27: val_loss improved from 0.05709 to 0.05628, saving model to AE_reduced_dataset_1_27_0.06.hdf5\n",
            "11/11 [==============================] - 5s 418ms/step - loss: 0.0566 - val_loss: 0.0563\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0557\n",
            "Epoch 28: val_loss improved from 0.05628 to 0.05495, saving model to AE_reduced_dataset_1_28_0.05.hdf5\n",
            "11/11 [==============================] - 6s 566ms/step - loss: 0.0557 - val_loss: 0.0549\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0544\n",
            "Epoch 29: val_loss improved from 0.05495 to 0.05374, saving model to AE_reduced_dataset_1_29_0.05.hdf5\n",
            "11/11 [==============================] - 7s 574ms/step - loss: 0.0544 - val_loss: 0.0537\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0532\n",
            "Epoch 30: val_loss improved from 0.05374 to 0.05313, saving model to AE_reduced_dataset_1_30_0.05.hdf5\n",
            "11/11 [==============================] - 5s 441ms/step - loss: 0.0532 - val_loss: 0.0531\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0527\n",
            "Epoch 31: val_loss improved from 0.05313 to 0.05257, saving model to AE_reduced_dataset_1_31_0.05.hdf5\n",
            "11/11 [==============================] - 7s 634ms/step - loss: 0.0527 - val_loss: 0.0526\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0521\n",
            "Epoch 32: val_loss improved from 0.05257 to 0.05241, saving model to AE_reduced_dataset_1_32_0.05.hdf5\n",
            "11/11 [==============================] - 5s 477ms/step - loss: 0.0521 - val_loss: 0.0524\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0516\n",
            "Epoch 33: val_loss improved from 0.05241 to 0.05186, saving model to AE_reduced_dataset_1_33_0.05.hdf5\n",
            "11/11 [==============================] - 6s 573ms/step - loss: 0.0516 - val_loss: 0.0519\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0510\n",
            "Epoch 34: val_loss improved from 0.05186 to 0.05149, saving model to AE_reduced_dataset_1_34_0.05.hdf5\n",
            "11/11 [==============================] - 6s 511ms/step - loss: 0.0510 - val_loss: 0.0515\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0503\n",
            "Epoch 35: val_loss improved from 0.05149 to 0.05090, saving model to AE_reduced_dataset_1_35_0.05.hdf5\n",
            "11/11 [==============================] - 5s 489ms/step - loss: 0.0503 - val_loss: 0.0509\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0497\n",
            "Epoch 36: val_loss improved from 0.05090 to 0.05062, saving model to AE_reduced_dataset_1_36_0.05.hdf5\n",
            "11/11 [==============================] - 7s 606ms/step - loss: 0.0497 - val_loss: 0.0506\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0495\n",
            "Epoch 37: val_loss did not improve from 0.05062\n",
            "11/11 [==============================] - 5s 460ms/step - loss: 0.0495 - val_loss: 0.0507\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0494\n",
            "Epoch 38: val_loss did not improve from 0.05062\n",
            "11/11 [==============================] - 7s 609ms/step - loss: 0.0494 - val_loss: 0.0514\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0490\n",
            "Epoch 39: val_loss improved from 0.05062 to 0.04945, saving model to AE_reduced_dataset_1_39_0.05.hdf5\n",
            "11/11 [==============================] - 5s 478ms/step - loss: 0.0490 - val_loss: 0.0494\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0482\n",
            "Epoch 40: val_loss improved from 0.04945 to 0.04940, saving model to AE_reduced_dataset_1_40_0.05.hdf5\n",
            "11/11 [==============================] - 8s 753ms/step - loss: 0.0482 - val_loss: 0.0494\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0476\n",
            "Epoch 41: val_loss improved from 0.04940 to 0.04852, saving model to AE_reduced_dataset_1_41_0.05.hdf5\n",
            "11/11 [==============================] - 9s 604ms/step - loss: 0.0476 - val_loss: 0.0485\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0470\n",
            "Epoch 42: val_loss improved from 0.04852 to 0.04832, saving model to AE_reduced_dataset_1_42_0.05.hdf5\n",
            "11/11 [==============================] - 7s 576ms/step - loss: 0.0470 - val_loss: 0.0483\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0466\n",
            "Epoch 43: val_loss improved from 0.04832 to 0.04789, saving model to AE_reduced_dataset_1_43_0.05.hdf5\n",
            "11/11 [==============================] - 7s 608ms/step - loss: 0.0466 - val_loss: 0.0479\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0459\n",
            "Epoch 44: val_loss improved from 0.04789 to 0.04711, saving model to AE_reduced_dataset_1_44_0.05.hdf5\n",
            "11/11 [==============================] - 6s 513ms/step - loss: 0.0459 - val_loss: 0.0471\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0452\n",
            "Epoch 45: val_loss improved from 0.04711 to 0.04681, saving model to AE_reduced_dataset_1_45_0.05.hdf5\n",
            "11/11 [==============================] - 7s 653ms/step - loss: 0.0452 - val_loss: 0.0468\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0446\n",
            "Epoch 46: val_loss improved from 0.04681 to 0.04620, saving model to AE_reduced_dataset_1_46_0.05.hdf5\n",
            "11/11 [==============================] - 5s 431ms/step - loss: 0.0446 - val_loss: 0.0462\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0441\n",
            "Epoch 47: val_loss improved from 0.04620 to 0.04602, saving model to AE_reduced_dataset_1_47_0.05.hdf5\n",
            "11/11 [==============================] - 7s 610ms/step - loss: 0.0441 - val_loss: 0.0460\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0434\n",
            "Epoch 48: val_loss improved from 0.04602 to 0.04539, saving model to AE_reduced_dataset_1_48_0.05.hdf5\n",
            "11/11 [==============================] - 6s 520ms/step - loss: 0.0434 - val_loss: 0.0454\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0434\n",
            "Epoch 49: val_loss did not improve from 0.04539\n",
            "11/11 [==============================] - 6s 504ms/step - loss: 0.0434 - val_loss: 0.0460\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0431\n",
            "Epoch 50: val_loss improved from 0.04539 to 0.04469, saving model to AE_reduced_dataset_1_50_0.04.hdf5\n",
            "11/11 [==============================] - 7s 662ms/step - loss: 0.0431 - val_loss: 0.0447\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0421\n",
            "Epoch 51: val_loss improved from 0.04469 to 0.04428, saving model to AE_reduced_dataset_1_51_0.04.hdf5\n",
            "11/11 [==============================] - 6s 536ms/step - loss: 0.0421 - val_loss: 0.0443\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0416\n",
            "Epoch 52: val_loss improved from 0.04428 to 0.04400, saving model to AE_reduced_dataset_1_52_0.04.hdf5\n",
            "11/11 [==============================] - 7s 627ms/step - loss: 0.0416 - val_loss: 0.0440\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0410\n",
            "Epoch 53: val_loss improved from 0.04400 to 0.04375, saving model to AE_reduced_dataset_1_53_0.04.hdf5\n",
            "11/11 [==============================] - 6s 534ms/step - loss: 0.0410 - val_loss: 0.0437\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0405\n",
            "Epoch 54: val_loss improved from 0.04375 to 0.04344, saving model to AE_reduced_dataset_1_54_0.04.hdf5\n",
            "11/11 [==============================] - 7s 640ms/step - loss: 0.0405 - val_loss: 0.0434\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0399\n",
            "Epoch 55: val_loss improved from 0.04344 to 0.04293, saving model to AE_reduced_dataset_1_55_0.04.hdf5\n",
            "11/11 [==============================] - 6s 524ms/step - loss: 0.0399 - val_loss: 0.0429\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0394\n",
            "Epoch 56: val_loss improved from 0.04293 to 0.04275, saving model to AE_reduced_dataset_1_56_0.04.hdf5\n",
            "11/11 [==============================] - 7s 601ms/step - loss: 0.0394 - val_loss: 0.0428\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0391\n",
            "Epoch 57: val_loss improved from 0.04275 to 0.04249, saving model to AE_reduced_dataset_1_57_0.04.hdf5\n",
            "11/11 [==============================] - 6s 557ms/step - loss: 0.0391 - val_loss: 0.0425\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0387\n",
            "Epoch 58: val_loss improved from 0.04249 to 0.04206, saving model to AE_reduced_dataset_1_58_0.04.hdf5\n",
            "11/11 [==============================] - 5s 477ms/step - loss: 0.0387 - val_loss: 0.0421\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0381\n",
            "Epoch 59: val_loss improved from 0.04206 to 0.04203, saving model to AE_reduced_dataset_1_59_0.04.hdf5\n",
            "11/11 [==============================] - 7s 650ms/step - loss: 0.0381 - val_loss: 0.0420\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0380\n",
            "Epoch 60: val_loss improved from 0.04203 to 0.04182, saving model to AE_reduced_dataset_1_60_0.04.hdf5\n",
            "11/11 [==============================] - 5s 491ms/step - loss: 0.0380 - val_loss: 0.0418\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0378\n",
            "Epoch 61: val_loss improved from 0.04182 to 0.04160, saving model to AE_reduced_dataset_1_61_0.04.hdf5\n",
            "11/11 [==============================] - 9s 825ms/step - loss: 0.0378 - val_loss: 0.0416\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0369\n",
            "Epoch 62: val_loss did not improve from 0.04160\n",
            "11/11 [==============================] - 5s 456ms/step - loss: 0.0369 - val_loss: 0.0416\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0366\n",
            "Epoch 63: val_loss improved from 0.04160 to 0.04119, saving model to AE_reduced_dataset_1_63_0.04.hdf5\n",
            "11/11 [==============================] - 6s 545ms/step - loss: 0.0366 - val_loss: 0.0412\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0365\n",
            "Epoch 64: val_loss did not improve from 0.04119\n",
            "11/11 [==============================] - 6s 517ms/step - loss: 0.0365 - val_loss: 0.0414\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0362\n",
            "Epoch 65: val_loss improved from 0.04119 to 0.04089, saving model to AE_reduced_dataset_1_65_0.04.hdf5\n",
            "11/11 [==============================] - 5s 468ms/step - loss: 0.0362 - val_loss: 0.0409\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0356\n",
            "Epoch 66: val_loss improved from 0.04089 to 0.04063, saving model to AE_reduced_dataset_1_66_0.04.hdf5\n",
            "11/11 [==============================] - 7s 626ms/step - loss: 0.0356 - val_loss: 0.0406\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0350\n",
            "Epoch 67: val_loss improved from 0.04063 to 0.04053, saving model to AE_reduced_dataset_1_67_0.04.hdf5\n",
            "11/11 [==============================] - 6s 524ms/step - loss: 0.0350 - val_loss: 0.0405\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0345\n",
            "Epoch 68: val_loss did not improve from 0.04053\n",
            "11/11 [==============================] - 5s 494ms/step - loss: 0.0345 - val_loss: 0.0409\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0342\n",
            "Epoch 69: val_loss improved from 0.04053 to 0.04050, saving model to AE_reduced_dataset_1_69_0.04.hdf5\n",
            "11/11 [==============================] - 5s 480ms/step - loss: 0.0342 - val_loss: 0.0405\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0340\n",
            "Epoch 70: val_loss improved from 0.04050 to 0.04038, saving model to AE_reduced_dataset_1_70_0.04.hdf5\n",
            "11/11 [==============================] - 6s 561ms/step - loss: 0.0340 - val_loss: 0.0404\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0345\n",
            "Epoch 71: val_loss did not improve from 0.04038\n",
            "11/11 [==============================] - 7s 662ms/step - loss: 0.0345 - val_loss: 0.0412\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0342\n",
            "Epoch 72: val_loss did not improve from 0.04038\n",
            "11/11 [==============================] - 6s 515ms/step - loss: 0.0342 - val_loss: 0.0405\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0338\n",
            "Epoch 73: val_loss did not improve from 0.04038\n",
            "11/11 [==============================] - 7s 654ms/step - loss: 0.0338 - val_loss: 0.0405\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0335\n",
            "Epoch 74: val_loss did not improve from 0.04038\n",
            "11/11 [==============================] - 6s 524ms/step - loss: 0.0335 - val_loss: 0.0407\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0331\n",
            "Epoch 75: val_loss did not improve from 0.04038\n",
            "11/11 [==============================] - 6s 503ms/step - loss: 0.0331 - val_loss: 0.0405\n",
            "9/9 [==============================] - 1s 46ms/step\n",
            "(287, 100)\n",
            "                   0    1    2    3         4\n",
            "TCGA.04.1341.01  0.0  0.0  0.0  0.0  0.410880\n",
            "TCGA.04.1343.01  0.0  0.0  0.0  0.0  0.298391\n",
            "TCGA.04.1348.01  0.0  0.0  0.0  0.0  0.000000\n",
            "TCGA.04.1356.01  0.0  0.0  0.0  0.0  0.000000\n",
            "TCGA.04.1357.01  0.0  0.0  0.0  0.0  0.000000\n",
            "Training Loss:  0.03311310335993767\n",
            "Validation Loss:  0.040462590754032135\n"
          ]
        }
      ]
    }
  ]
}